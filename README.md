*******************************************************************************************************************
						
						     IR FOR TEXT ANALYSIS

						     By:- Abhishek Kharche


*******************************************************************************************************************

This is the project to implement Information Retrieval for text analysis. I used open source Java Software 
jEdit4.3 for text analysis. The project extracts the method contents from the source and creates a corpus of 
possible terms after splitting and stemming the words. This corpus is then parsed and cosine similarity against 
user queries for each document is found. These results are then compared against the GoldSets which are the sets 
evaluated by someone in past years.
Scripting Language:- Perl, Shell scripting.

*******************************************************************************************************************
					              FILES IN THE PROJECT
*******************************************************************************************************************

Source Files:- 	1. norm_tf.pl
		2. wdf.pl
		3. query_as_a_vector.pl
		4. similarity.pl
		5. VSM.pl
		6. VSM_effectiveness.pl

Text Files:-	1. norm_tf.txt
		2. wdf.txt
		3. tf_transpose.txt
		4. query_as_a_vector.txt
		5. similarity.txt
		6. VSM.txt
		7. VSM_effectiveness.txt (can be used to make csv file)

*******************************************************************************************************************
						       IMPLEMENTATION
*******************************************************************************************************************

There are 6 source files in this project. The implementation for all of them are as follow;

1. The first file (norm_tf.pl) make use of "CorpusMethods-jEdit4.3-AfterSplitStopStem.txt" file in 	  		   
   "jEdit4.3" directory and generates norm_tf.txt file. This file contains a matrix of 6413*3179 where 6413 	 	   
   are number of documents and 3179 are number of unique terms. The value for specified row column pair is 	 	   
   the respective normalized tf value. The file generated by this code needs to be transposed for simplicity 	  	   
   in calculating wdf. The transposed file "tf_transpose.txt" is provided in this folder. It can be 	  	       
   transposed manually in Excel or with the source code (not included).
	
2. "wdf.pl" is used to calculate weighted document frequency. It make use of "norm_tf.txt" generated by last 	  	   
   source code run. The result for this program is "wdf.txt" which contains a matrix of 6413*3179 delimeted 	  	   
   by tab.

3. The next source code file "query_as_a_vector.pl" is to create a vector for the user inpout. This file 	 	   
   creates a matrix of 150*3179 dimensions to store values for each unique term found from 150 inputs in all 	  	   
   documents in corpus. This program use "CorpusQueries-jEdit4.3-AfterSplitStopStem.txt" and 	  	 	       
   "CorpusMethods-jEdit4.3-AfterSplitStopStem.txt" from "jEdit4.3" directory

4. "similarity.pl" is used to create "similarity.txt" file. This code implements the formula for similarity 	  	   
   and by using "wdf.txt" and "query_as_a_vector.txt" it generates "similarity.txt" which is the file of 	  	   
   approx 1 Million lines. (Note that this program takes more than 4 hours for execution because it contains 	  	   
   nearly 6413*3179*150 repetations of complex similarity formula).

5. "VSM.pl" sorts the "similarity.txt" file according to the similarity values and retains its document 	       
   number and provides the position for each document which can be used to generate results of effectiveness.

6. Finally, "VSM_effectiveness.pl" is used to make the csv file in 5 column formats. This code make use of 	       
   "VSM.txt"generated in last program, "CorpusMethods-jEdit4.3.mapping" and "jEdit4.3ListOfFeatureIDs.txt" 	       
   files from "jEdit4.3" directory. This file produces "VSM_effectiveness.txt" file which can be opened in 	       
   Excel for better view.

*******************************************************************************************************************
						       How TO RUN
*******************************************************************************************************************

You must have perl compiler installed in your system.
You can get perl from:- http://www.perl.org/get.html

Following command can be used to run any perl file:-

$> perl "filepath/filename"

Note:- You don't have to pass the files as an input as all the file paths which are used in program are hard coded 
in the programs. But you have to make sure that you save them in the same catagory. If you want to check 
compilation errors you can give command as follows:- perl -c "filepath/filename"

*******************************************************************************************************************
						        THANK YOU
*******************************************************************************************************************



